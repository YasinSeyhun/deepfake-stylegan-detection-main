# ğŸ›¡ï¸ Federated Deepfake Detection System

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg?style=for-the-badge&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED.svg?style=for-the-badge&logo=Docker&logoColor=white)
![Next.js](https://img.shields.io/badge/Next.js-black.svg?style=for-the-badge&logo=next.js&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green.svg?style=for-the-badge)

A privacy-preserving **Federated Learning system** designed to verify the authenticity of images and detect deepfakes generated by **StyleGAN**. This project leverages **ResNet50** as the backbone model, aggregating gradients from multiple clients to train a robust global model without ever sharing raw local data.

---

## ğŸ—ï¸ System Architecture

The system follows a star topology where a central server orchestrates the training process across multiple distributed clients.

```mermaid
graph TD
    User((User)) -->|Upload Image| WebApp[Next.js WebApp]
    WebApp -->|HTTP API| Backend[FastAPI Backend]
    
    subgraph "Inference Environment"
        Backend -->|Load Weights| GlobalModel[Global ResNet50 Model]
        GlobalModel -->|Prediction| Backend
        Backend -->|Grad-CAM| Visualization[Heatmap Generation]
    end
    
    subgraph "Federated Training Environment"
        Server[FL Server]
        
        Client1[Client Node 1] <-->|gRPC / Net param| Server
        Client2[Client Node 2] <-->|gRPC / Net param| Server
        
        LocalData1[(Client 1 Data)] --> Client1
        LocalData2[(Client 2 Data)] --> Client2
    end
    
    Server -.->|Deploy Global Weights| GlobalModel
    
    style Server fill:#f9f,stroke:#333,stroke-width:2px
    style GlobalModel fill:#bbf,stroke:#333,stroke-width:2px
```

### Component Flow
1.  **Federated Learning**: The **Server** initializes the global model parameters. **Clients** download these parameters, train locally on their private datasets (StyleGAN vs Real), and send updated weights back to the server.
2.  **Aggregation**: The Server aggregates these updates (using FedAvg strategy) to improve the Global Model.
3.  **Deployment**: The updated Global Model is made available to the **Backend**.
4.  **Inference**: Users interact with the **WebApp** to upload suspicious images. The **Backend** processes the image using the Global Model and returns a probability score along with a Grad-CAM heatmap explaining the decision.

---

## âœ¨ Key Features

*   **ğŸ”’ Privacy-First**: Utilizes Federated Learning to ensure raw training data never leaves the client's device.
*   **ğŸ§  Advanced Detection**: Fine-tuned **ResNet50** architecture optimized for detecting GAN-generated artifacts.
*   **ğŸ³ Fully Containerized**: Dockerized microservices architecture for effortless deployment and scaling.
*   **ğŸ‘ï¸ Explainable AI**: Integrated **Grad-CAM** (Gradient-weighted Class Activation Mapping) to visualize which parts of the image influenced the model's decision.
*   **âš¡ Modern Stack**: Built with **Python 3.9**, **PyTorch**, **FastAPI**, and **Next.js**.

---

## ğŸš€ Quick Start

This system is designed to be run with **Docker Compose**. For detailed deployment instructions, including port configurations and troubleshooting, please refer to the **[Deployment Guide](DOCKER.md)**.

### 1-Click Run
```bash
# Clone the repository
git clone https://github.com/yourusername/deepfake-stylegan-detection.git

# Build and start services
docker-compose up --build
```

Access the application at **[http://localhost:3000](http://localhost:3000)**.

---

## ğŸ“‚ Project Structure

```bash
.
â”œâ”€â”€ server/                 # ğŸ§  Federated Learning Server (Orchestrator)
â”œâ”€â”€ client_machine/         # ğŸ’» Federated Client Node (Local Training)
â”œâ”€â”€ backend/                # ğŸš€ FastAPI Backend (Inference & API)
â”œâ”€â”€ webapp/                 # ğŸŒ Next.js Frontend (User Interface)
â”œâ”€â”€ src/                    # ğŸ“¦ Shared Source Code (Models, Configs)
â”œâ”€â”€ docker-compose.yml      # ğŸ³ Container Orchestration Config
â”œâ”€â”€ README.md               # ğŸ“– Project Documentation
â””â”€â”€ DOCKER.md               # ğŸ› ï¸ Deployment Guide
```

---

## ğŸ›¡ï¸ Security

The system implements basic security measures for the federated environment:
*   **JWT Authentication**: Clients must authenticate with the server using a shared `SECRET_KEY`.
*   **Token Validation**: The server rejects updates from unauthorized clients.

To configure security, update the `SECRET_KEY` in your `.env` file.

---

## ğŸ“ˆ Monitoring

Training progress is logged to the console and saved in the `runs/` directory. You can monitor:
*   Global Model Accuracy/Loss per round.
*   Client connectivity statuses.
*   Aggregation latency.

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:
1.  Fork the repository.
2.  Create a feature branch (`git checkout -b feature/AmazingFeature`).
3.  Commit your changes (`git commit -m 'Add some AmazingFeature'`).
4.  Push to the branch (`git push origin feature/AmazingFeature`).
5.  Open a Pull Request.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
